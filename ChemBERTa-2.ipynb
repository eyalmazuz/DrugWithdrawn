{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2541e7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5281a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "import wandb\n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer, IntervalStrategy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be779376",
   "metadata": {},
   "source": [
    "Loading the metrics we'll use to evaluate our model's training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fae6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = evaluate.load(\"roc_auc\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precison = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc856ae",
   "metadata": {},
   "source": [
    "Here we decide with evaluation to use and with dataset to test on\n",
    "\n",
    "In addition, we load the pre-trained model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fe51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_type = 'db_agree_no_dups'\n",
    "dataset_name = 'NCATS'\n",
    "pretrained_path = \"DeepChem/ChemBERTa-77M-MTR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e2c52",
   "metadata": {},
   "source": [
    "here we load the dataset, we use train2 since it's the train file that doesn't contain the validation set insode of it.\n",
    "\n",
    "this ``load_dataset`` method, automatically loads all the files in csv format and creates an HuggingFace's dataset object that is easy to use when fine-tuning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8aee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'split/{split_type}/{dataset_name}/train2.csv',\n",
    "                                          'validation': f'split/{split_type}/{dataset_name}/val.csv',\n",
    "                                          'test': f'split/{split_type}/{dataset_name}/test.csv',})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a302d5e5",
   "metadata": {},
   "source": [
    "removing uncessencary columns from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9b482f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column('withdrawn_class', 'labels').\\\n",
    "            remove_columns(['Unnamed: 0', 'index', 'length', 'inchikey', 'name', 'groups', 'source']).\\\n",
    "            with_format('torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579dc7c3",
   "metadata": {},
   "source": [
    "here we load our model and tokenizer, we use the ``AutoModel`` and ``AutoTokenizer`` classes as they provide a generic way to load every model in HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_path, num_labels=2,\n",
    "                                                           id2label={0: 'Not Withdrawn', 1:'Withdrawn'},\n",
    "                                                           label2id={'Not Withdrawn': 0, 'Withdrawn': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df06cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015dff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"this methods tokenize the smiles into ids which are then fed into the transforemr model\n",
    "    we set the max length of the toknizer to be the longest SMILES in our dataset and pad the rest to this length\"\"\"\n",
    "    return tokenizer(examples[\"smiles\"], padding=\"max_length\", truncation=True, max_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(tokenize_function, batched=True).remove_columns(['smiles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98baad22",
   "metadata": {},
   "source": [
    "a method to compute all the metrics we are using to evaluate our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy_score = accuracy.compute(predictions=predictions, references=labels)\n",
    "    auc_score = auc.compute(prediction_scores=logits[:, 1], references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels)\n",
    "    aupr = average_precision_score(y_score=logits[:, 1], y_true=labels)\n",
    "    precision_score = precison.compute(predictions=predictions, references=labels)\n",
    "    recall_score = recall.compute(predictions=predictions, references=labels)\n",
    "    return {**f1_score , **{'PR-AUC': aupr}, **accuracy_score, **auc_score, **precision_score, **recall_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9758dc45",
   "metadata": {},
   "source": [
    "here we define our entire training arguments\n",
    "this is a simple HuggingFace object that will contain all the parameters we are using in our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./results/{split_type}/{dataset_name}/{pretrained_path}\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=IntervalStrategy.STEPS,\n",
    "    save_strategy=IntervalStrategy.STEPS,\n",
    "    report_to='wandb',\n",
    "    run_name=f'{pretrained_path} {split_type} {dataset_name}',\n",
    "    logging_steps=50,\n",
    "    save_steps=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca5eac",
   "metadata": {},
   "source": [
    "training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfeaf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset={'Validation': dataset[\"validation\"], 'Test': dataset[\"test\"]},\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4145d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddeb0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
